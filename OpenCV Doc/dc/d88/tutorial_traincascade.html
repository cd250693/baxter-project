<!-- HTML header for doxygen 1.8.6-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.6"/>
<title>OpenCV: Cascade Classifier Training</title>
<link href="../../opencv.ico" rel="shortcut icon" type="image/x-icon" />
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { searchBox.OnSelectItem(0); });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
MathJax.Hub.Config(
{
  TeX: {
      Macros: {
          matTT: [ "\\[ \\left|\\begin{array}{ccc} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{array}\\right| \\]", 9],
          fork: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ \\end{array} \\right.", 4],
          forkthree: ["\\left\\{ \\begin{array}{l l} #1 & \\mbox{#2}\\\\ #3 & \\mbox{#4}\\\\ #5 & \\mbox{#6}\\\\ \\end{array} \\right.", 6],
          vecthree: ["\\begin{bmatrix} #1\\\\ #2\\\\ #3 \\end{bmatrix}", 3],
          vecthreethree: ["\\begin{bmatrix} #1 & #2 & #3\\\\ #4 & #5 & #6\\\\ #7 & #8 & #9 \\end{bmatrix}", 9],
          hdotsfor: ["\\dots", 1],
          mathbbm: ["\\mathbb{#1}", 1],
          bordermatrix: ["\\matrix{#1}", 1]
      }
  }
}
);
</script><script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../stylesheet.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="../../opencv-logo-small.png"/></td>
  <td style="padding-left: 0.5em;">
   <div id="projectname">OpenCV
   &#160;<span id="projectnumber">3.0.0</span>
   </div>
   <div id="projectbrief">Open Source Computer Vision</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.6 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "../../search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="../../index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="../../pages.html"><span>Related&#160;Pages</span></a></li>
      <li><a href="../../modules.html"><span>Modules</span></a></li>
      <li><a href="../../namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="../../annotated.html"><span>Classes</span></a></li>
      <li><a href="../../files.html"><span>Files</span></a></li>
      <li><a href="../../examples.html"><span>Examples</span></a></li>
      <li><a href="../..//3.0-last-rst"><span>Sphinx&#160;Documentation</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="../../search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="../../search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
<a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(0)"><span class="SelectionMark">&#160;</span>All</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(1)"><span class="SelectionMark">&#160;</span>Classes</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(2)"><span class="SelectionMark">&#160;</span>Namespaces</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(3)"><span class="SelectionMark">&#160;</span>Files</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(4)"><span class="SelectionMark">&#160;</span>Functions</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(5)"><span class="SelectionMark">&#160;</span>Variables</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(6)"><span class="SelectionMark">&#160;</span>Typedefs</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(7)"><span class="SelectionMark">&#160;</span>Enumerations</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(8)"><span class="SelectionMark">&#160;</span>Enumerator</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(9)"><span class="SelectionMark">&#160;</span>Properties</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(10)"><span class="SelectionMark">&#160;</span>Friends</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(11)"><span class="SelectionMark">&#160;</span>Macros</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(12)"><span class="SelectionMark">&#160;</span>Groups</a><a class="SelectItem" href="javascript:void(0)" onclick="searchBox.OnSelectItem(13)"><span class="SelectionMark">&#160;</span>Pages</a></div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../d9/df8/tutorial_root.html">OpenCV Tutorials</a></li><li class="navelem"><a class="el" href="../../d2/d64/tutorial_table_of_content_objdetect.html">Object Detection (objdetect module)</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Cascade Classifier Training </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h2>Introduction </h2>
<p>The work with a cascade classifier inlcudes two major stages: training and detection. Detection stage is described in a documentation of objdetect module of general OpenCV documentation. Documentation gives some basic information about cascade classifier. Current guide is describing how to train a cascade classifier: preparation of the training data and running the training application.</p>
<h3>Important notes</h3>
<p>There are two applications in OpenCV to train cascade classifier: opencv_haartraining and opencv_traincascade. opencv_traincascade is a newer version, written in C++ in accordance to OpenCV 2.x API. But the main difference between this two applications is that opencv_traincascade supports both Haar <a class="el" href="../../d0/de3/citelist.html#CITEREF_Viola01">Viola01</a> and <a class="el" href="../../d0/de3/citelist.html#CITEREF_Liao2007">Liao2007</a> (Local Binary Patterns) features. LBP features are integer in contrast to Haar features, so both training and detection with LBP are several times faster then with Haar features. Regarding the LBP and Haar detection quality, it depends on training: the quality of training dataset first of all and training parameters too. It's possible to train a LBP-based classifier that will provide almost the same quality as Haar-based one.</p>
<p>opencv_traincascade and opencv_haartraining store the trained classifier in different file formats. Note, the newer cascade detection interface (see CascadeClassifier class in objdetect module) support both formats. opencv_traincascade can save (export) a trained cascade in the older format. But opencv_traincascade and opencv_haartraining can not load (import) a classifier in another format for the futher training after interruption.</p>
<p>Note that opencv_traincascade application can use TBB for multi-threading. To use it in multicore mode OpenCV must be built with TBB.</p>
<p>Also there are some auxilary utilities related to the training.</p>
<ul>
<li>opencv_createsamples is used to prepare a training dataset of positive and test samples. opencv_createsamples produces dataset of positive samples in a format that is supported by both opencv_haartraining and opencv_traincascade applications. The output is a file with *.vec extension, it is a binary format which contains images.</li>
<li>opencv_performance may be used to evaluate the quality of classifiers, but for trained by opencv_haartraining only. It takes a collection of marked up images, runs the classifier and reports the performance, i.e. number of found objects, number of missed objects, number of false alarms and other information.</li>
</ul>
<p>Since opencv_haartraining is an obsolete application, only opencv_traincascade will be described futher. opencv_createsamples utility is needed to prepare a training data for opencv_traincascade, so it will be described too.</p>
<h2>Training data preparation </h2>
<p>For training we need a set of samples. There are two types of samples: negative and positive. Negative samples correspond to non-object images. Positive samples correspond to images with detected objects. Set of negative samples must be prepared manually, whereas set of positive samples is created using opencv_createsamples utility.</p>
<h3>Negative Samples</h3>
<p>Negative samples are taken from arbitrary images. These images must not contain detected objects. Negative samples are enumerated in a special file. It is a text file in which each line contains an image filename (relative to the directory of the description file) of negative sample image. This file must be created manually. Note that negative samples and sample images are also called background samples or background images, and are used interchangeably in this document. Described images may be of different sizes. But each image should be (but not nessesarily) larger than a training window size, because these images are used to subsample negative image to the training size.</p>
<p>An example of description file:</p>
<p>Directory structure: </p>
<div class="fragment"><div class="line">/img</div>
<div class="line">  img1.jpg</div>
<div class="line">  img2.jpg</div>
<div class="line">bg.txt</div>
</div><!-- fragment --><p> File bg.txt: </p>
<div class="fragment"><div class="line">img/img1.jpg</div>
<div class="line">img/img2.jpg</div>
</div><!-- fragment --> <h3>Positive Samples</h3>
<p>Positive samples are created by opencv_createsamples utility. They may be created from a single image with object or from a collection of previously marked up images.</p>
<p>Please note that you need a large dataset of positive samples before you give it to the mentioned utility, because it only applies perspective transformation. For example you may need only one positive sample for absolutely rigid object like an OpenCV logo, but you definetely need hundreds and even thousands of positive samples for faces. In the case of faces you should consider all the race and age groups, emotions and perhaps beard styles.</p>
<p>So, a single object image may contain a company logo. Then a large set of positive samples is created from the given object image by random rotating, changing the logo intensity as well as placing the logo on arbitrary background. The amount and range of randomness can be controlled by command line arguments of opencv_createsamples utility.</p>
<p>Command line arguments:</p>
<ul>
<li><p class="startli">-vec &lt;vec_file_name&gt;</p>
<p class="startli">Name of the output file containing the positive samples for training.</p>
</li>
<li><p class="startli">-img &lt;image_file_name&gt;</p>
<p class="startli">Source object image (e.g., a company logo).</p>
</li>
<li><p class="startli">-bg &lt;background_file_name&gt;</p>
<p class="startli">Background description file; contains a list of images which are used as a background for randomly distorted versions of the object.</p>
</li>
<li><p class="startli">-num &lt;number_of_samples&gt;</p>
<p class="startli">Number of positive samples to generate.</p>
</li>
<li><p class="startli">-bgcolor &lt;background_color&gt;</p>
<p class="startli">Background color (currently grayscale images are assumed); the background color denotes the transparent color. Since there might be compression artifacts, the amount of color tolerance can be specified by -bgthresh. All pixels withing bgcolor-bgthresh and bgcolor+bgthresh range are interpreted as transparent.</p>
</li>
<li>-bgthresh &lt;background_color_threshold&gt;</li>
<li><p class="startli">-inv</p>
<p class="startli">If specified, colors will be inverted.</p>
</li>
<li><p class="startli">-randinv</p>
<p class="startli">If specified, colors will be inverted randomly.</p>
</li>
<li><p class="startli">-maxidev &lt;max_intensity_deviation&gt;</p>
<p class="startli">Maximal intensity deviation of pixels in foreground samples.</p>
</li>
<li>-maxxangle &lt;max_x_rotation_angle&gt;</li>
<li>-maxyangle &lt;max_y_rotation_angle&gt;</li>
<li><p class="startli">-maxzangle &lt;max_z_rotation_angle&gt;</p>
<p class="startli">Maximum rotation angles must be given in radians.</p>
</li>
<li><p class="startli">-show</p>
<p class="startli">Useful debugging option. If specified, each sample will be shown. Pressing Esc will continue the samples creation process without.</p>
</li>
<li><p class="startli">-w &lt;sample_width&gt;</p>
<p class="startli">Width (in pixels) of the output samples.</p>
</li>
<li><p class="startli">-h &lt;sample_height&gt;</p>
<p class="startli">Height (in pixels) of the output samples.</p>
</li>
</ul>
<p>For following procedure is used to create a sample object instance: The source image is rotated randomly around all three axes. The chosen angle is limited my -max?angle. Then pixels having the intensity from [bg_color-bg_color_threshold; bg_color+bg_color_threshold] range are interpreted as transparent. White noise is added to the intensities of the foreground. If the -inv key is specified then foreground pixel intensities are inverted. If -randinv key is specified then algorithm randomly selects whether inversion should be applied to this sample. Finally, the obtained image is placed onto an arbitrary background from the background description file, resized to the desired size specified by -w and -h and stored to the vec-file, specified by the -vec command line option.</p>
<p>Positive samples also may be obtained from a collection of previously marked up images. This collection is described by a text file similar to background description file. Each line of this file corresponds to an image. The first element of the line is the filename. It is followed by the number of object instances. The following numbers are the coordinates of objects bounding rectangles (x, y, width, height).</p>
<p>An example of description file:</p>
<p>Directory structure: </p>
<div class="fragment"><div class="line">/img</div>
<div class="line">  img1.jpg</div>
<div class="line">  img2.jpg</div>
<div class="line">info.dat</div>
</div><!-- fragment --><p> File info.dat: </p>
<div class="fragment"><div class="line">img/img1.jpg  1  140 100 45 45</div>
<div class="line">img/img2.jpg  2  100 200 50 50   50 30 25 25</div>
</div><!-- fragment --><p> Image img1.jpg contains single object instance with the following coordinates of bounding rectangle: (140, 100, 45, 45). Image img2.jpg contains two object instances.</p>
<p>In order to create positive samples from such collection, -info argument should be specified instead of `-img`:</p>
<ul>
<li><p class="startli">-info &lt;collection_file_name&gt;</p>
<p class="startli">Description file of marked up images collection.</p>
</li>
</ul>
<p>The scheme of samples creation in this case is as follows. The object instances are taken from images. Then they are resized to target samples size and stored in output vec-file. No distortion is applied, so the only affecting arguments are -w, -h, -show and -num.</p>
<p>opencv_createsamples utility may be used for examining samples stored in positive samples file. In order to do this only -vec, -w and -h parameters should be specified.</p>
<p>Note that for training, it does not matter how vec-files with positive samples are generated. But opencv_createsamples utility is the only one way to collect/create a vector file of positive samples, provided by OpenCV.</p>
<p>Example of vec-file is available here opencv/data/vec_files/trainingfaces_24-24.vec. It can be used to train a face detector with the following window size: -w 24 -h 24.</p>
<h2>Cascade Training </h2>
<p>The next step is the training of classifier. As mentioned above opencv_traincascade or opencv_haartraining may be used to train a cascade classifier, but only the newer opencv_traincascade will be described futher.</p>
<p>Command line arguments of opencv_traincascade application grouped by purposes:</p>
<ol type="1">
<li>Common arguments:<ul>
<li><p class="startli">-data &lt;cascade_dir_name&gt;</p>
<p class="startli">Where the trained classifier should be stored.</p>
</li>
<li><p class="startli">-vec &lt;vec_file_name&gt;</p>
<p class="startli">vec-file with positive samples (created by opencv_createsamples utility).</p>
</li>
<li><p class="startli">-bg &lt;background_file_name&gt;</p>
<p class="startli">Background description file.</p>
</li>
<li>-numPos &lt;number_of_positive_samples&gt;</li>
<li><p class="startli">-numNeg &lt;number_of_negative_samples&gt;</p>
<p class="startli">Number of positive/negative samples used in training for every classifier stage.</p>
</li>
<li><p class="startli">-numStages &lt;number_of_stages&gt;</p>
<p class="startli">Number of cascade stages to be trained.</p>
</li>
<li><p class="startli">-precalcValBufSize &lt;precalculated_vals_buffer_size_in_Mb&gt;</p>
<p class="startli">Size of buffer for precalculated feature values (in Mb).</p>
</li>
<li><p class="startli">-precalcIdxBufSize &lt;precalculated_idxs_buffer_size_in_Mb&gt;</p>
<p class="startli">Size of buffer for precalculated feature indices (in Mb). The more memory you have the faster the training process.</p>
</li>
<li><p class="startli">-baseFormatSave</p>
<p class="startli">This argument is actual in case of Haar-like features. If it is specified, the cascade will be saved in the old format.</p>
</li>
<li><p class="startli">-numThreads &lt;max_number_of_threads&gt;</p>
<p class="startli">Maximum number of threads to use during training. Notice that the actual number of used threads may be lower, depending on your machine and compilation options.</p>
</li>
<li><p class="startli">-acceptanceRatioBreakValue &lt;break_value&gt;</p>
<p class="startli">This argument is used to determine how precise your model should keep learning and when to stop. A good guideline is to train not further than 10e-5, to ensure the model does not overtrain on your training data. By default this value is set to -1 to disable this feature.</p>
</li>
</ul>
</li>
<li>Cascade parameters:<ul>
<li><p class="startli">-stageType &lt;BOOST(default)&gt;</p>
<p class="startli">Type of stages. Only boosted classifier are supported as a stage type at the moment.</p>
</li>
<li><p class="startli">-featureType&lt;{HAAR(default), LBP}&gt;</p>
<p class="startli">Type of features: HAAR - Haar-like features, LBP - local binary patterns.</p>
</li>
<li>-w &lt;sampleWidth&gt;</li>
<li><p class="startli">-h &lt;sampleHeight&gt;</p>
<p class="startli">Size of training samples (in pixels). Must have exactly the same values as used during training samples creation (opencv_createsamples utility).</p>
</li>
</ul>
</li>
<li>Boosted classifer parameters:<ul>
<li><p class="startli">-bt &lt;{DAB, RAB, LB, GAB(default)}&gt;</p>
<p class="startli">Type of boosted classifiers: DAB - Discrete AdaBoost, RAB - Real AdaBoost, LB - LogitBoost, GAB - Gentle AdaBoost.</p>
</li>
<li><p class="startli">-minHitRate &lt;min_hit_rate&gt;</p>
<p class="startli">Minimal desired hit rate for each stage of the classifier. Overall hit rate may be estimated as (min_hit_rate\^number_of_stages).</p>
</li>
<li><p class="startli">-maxFalseAlarmRate &lt;max_false_alarm_rate&gt;</p>
<p class="startli">Maximal desired false alarm rate for each stage of the classifier. Overall false alarm rate may be estimated as (max_false_alarm_rate\^number_of_stages).</p>
</li>
<li><p class="startli">-weightTrimRate &lt;weight_trim_rate&gt;</p>
<p class="startli">Specifies whether trimming should be used and its weight. A decent choice is 0.95.</p>
</li>
<li><p class="startli">-maxDepth &lt;max_depth_of_weak_tree&gt;</p>
<p class="startli">Maximal depth of a weak tree. A decent choice is 1, that is case of stumps.</p>
</li>
<li><p class="startli">-maxWeakCount &lt;max_weak_tree_count&gt;</p>
<p class="startli">Maximal count of weak trees for every cascade stage. The boosted classifier (stage) will have so many weak trees (&lt;=maxWeakCount), as needed to achieve the given -maxFalseAlarmRate.</p>
</li>
</ul>
</li>
<li>Haar-like feature parameters:<ul>
<li><p class="startli">-mode &lt;BASIC (default) | CORE | ALL&gt;</p>
<p class="startli">Selects the type of Haar features set used in training. BASIC use only upright features, while ALL uses the full set of upright and 45 degree rotated feature set. See <a class="el" href="../../d0/de3/citelist.html#CITEREF_Lienhart02">Lienhart02</a> for more details.</p>
</li>
</ul>
</li>
<li><p class="startli">Local Binary Patterns parameters:</p>
<p class="startli">Local Binary Patterns don't have parameters.</p>
</li>
</ol>
<p>After the opencv_traincascade application has finished its work, the trained cascade will be saved in cascade.xml file in the folder, which was passed as -data parameter. Other files in this folder are created for the case of interrupted training, so you may delete them after completion of training.</p>
<p>Training is finished and you can test you cascade classifier! </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.6-->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated on Sat Jun 20 2015 13:08:40 for OpenCV by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="../../doxygen.png" alt="doxygen"/>
</a> 1.8.6
</small></address>
</body>
</html>
